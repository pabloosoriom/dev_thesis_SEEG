{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from nltools.data import Brain_Data, Design_Matrix, Adjacency\n",
    "import networkx as nx\n",
    "from scipy import signal\n",
    "from mne_connectivity import spectral_connectivity_epochs\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import io\n",
    "from itertools import cycle\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import kendalltau\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "\n",
    "\n",
    "\n",
    "from functions.EpiIndex import *\n",
    "from functions.Connectivity import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw=mne.io.read_raw_fif('/home/pablo/works/dev_thesis_SEEG/data/pte_01/sets/segments_ictal_SR/ictal-epo_6.fif', preload=True)\n",
    "#Reading a npy file \n",
    "data_alpha = np.load('/home/pablo/works/dev_thesis_SEEG/outputs/pte_01/pte_01_connectivity_data_alpha_aec_dense.npy')\n",
    "data_beta = np.load('/home/pablo/works/dev_thesis_SEEG/outputs/pte_01/pte_01_connectivity_data_beta_aec_dense.npy')\n",
    "data_hgamma = np.load('/home/pablo/works/dev_thesis_SEEG/outputs/pte_01/pte_01_connectivity_data_high_gamma1_aec_dense.npy')\n",
    "data_lgamma = np.load('/home/pablo/works/dev_thesis_SEEG/outputs/pte_01/pte_01_connectivity_data_low_gamma_aec_dense.npy')\n",
    "data_theta = np.load('/home/pablo/works/dev_thesis_SEEG/outputs/pte_01/pte_01_connectivity_data_theta_aec_dense.npy')\n",
    "\n",
    "data_alpha_norm = np.load('/home/pablo/works/dev_thesis_SEEG/outputs/pte_01/pte_01_connectivity_data_alpha_aec_distance_dense.npy')\n",
    "data_beta_norm = np.load('/home/pablo/works/dev_thesis_SEEG/outputs/pte_01/pte_01_connectivity_data_beta_aec_distance_dense.npy')\n",
    "data_hgamma_norm = np.load('/home/pablo/works/dev_thesis_SEEG/outputs/pte_01/pte_01_connectivity_data_high_gamma1_aec_distance_dense.npy')\n",
    "data_lgamma_norm = np.load('/home/pablo/works/dev_thesis_SEEG/outputs/pte_01/pte_01_connectivity_data_low_gamma_aec_distance_dense.npy')\n",
    "data_theta_norm = np.load('/home/pablo/works/dev_thesis_SEEG/outputs/pte_01/pte_01_connectivity_data_theta_aec_distance_dense.npy')\n",
    "\n",
    "#Data with other metrics\n",
    "data_coh = np.load('/home/pablo/works/dev_thesis_SEEG/outputs/pte_01/SR_subseg_connectivity_data_high_freq_coh_dense.npy')[:,:,:,0]\n",
    "# Assuming data is the array with shape (50, 127, 127)\n",
    "for i in range(data_coh.shape[0]):\n",
    "    # Extract the lower triangular part (including the diagonal)\n",
    "    lower_triangular = np.tril(data_coh[i])\n",
    "    \n",
    "    # Mirror the lower triangular part to the upper triangular part\n",
    "    data_coh[i] = lower_triangular + lower_triangular.T - np.diag(np.diag(lower_triangular))\n",
    "\n",
    "#Make data_coh symmetric\n",
    "\n",
    "# con_data=np.mean(data,axis=3)\n",
    "raw=raw.drop_channels([\"lp'11\", \"lp'12\", \"op'12\", \"pi'18\", \"pa'12\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For this data set, we are going to get the temporal correlation of the channels inside, outside, inside vs outside\n",
    "#the SOZ\n",
    "ch_names=raw.ch_names\n",
    "data=data_lgamma_norm\n",
    "data.shape\n",
    "\n",
    "#Get the SOZ channels\n",
    "inside_channels=[\"sc'3\",\"sc'4\",\"sc'5\",\"sc'6\",\"y'5\",\"y'6\",\"y'7\",\"y'8\",\"y'9\"]\n",
    "#Get the channels outside the SOZ \n",
    "outside_channels=[ch for ch in raw.ch_names if ch not in inside_channels]\n",
    "\n",
    "#Get the indices of the channels\n",
    "inside_channels_idx=[ch_names.index(ch) for ch in inside_channels]\n",
    "outside_channels_idx=[ch_names.index(ch) for ch in outside_channels]\n",
    "\n",
    "#From data, get the subset of matrix with the channels inside the SOZ\n",
    "data_inside=data[:,inside_channels_idx,:][:,:,inside_channels_idx]\n",
    "#From data, get the subset of matrix with the channels outside the SOZ\n",
    "data_outside=data[:,outside_channels_idx,:][:,:,outside_channels_idx]\n",
    "\n",
    "#Get the correlation of the channels inside the SOZ\n",
    "correlation_inside = np.zeros((data.shape[0], data.shape[0]))\n",
    "for t1 in range(data.shape[0]):\n",
    "    for t2 in range(data.shape[0]):\n",
    "        upper_tri_1 = data_inside[t1, :, :][np.triu_indices_from(data_inside[t1, :, :], k=1)]\n",
    "        upper_tri_2 = data_inside[t2, :, :][np.triu_indices_from(data_inside[t2, :, :], k=1)]\n",
    "        correlation, _ = pearsonr(upper_tri_1, upper_tri_2)\n",
    "        correlation_inside[t1, t2] = correlation\n",
    "\n",
    "#Get the correlation of the channels outside the SOZ\n",
    "correlation_outside = np.zeros((data.shape[0], data.shape[0]))\n",
    "for t1 in range(data.shape[0]):\n",
    "    for t2 in range(data.shape[0]):\n",
    "        upper_tri_1 = data_outside[t1, :, :][np.triu_indices_from(data_outside[t1, :, :], k=1)]\n",
    "        upper_tri_2 = data_outside[t2, :, :][np.triu_indices_from(data_outside[t2, :, :], k=1)]\n",
    "        correlation, _ = pearsonr(upper_tri_1, upper_tri_2)\n",
    "        correlation_outside[t1, t2] = correlation\n",
    "\n",
    "\n",
    "\n",
    "#Plot the correlation matrices\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "sns.heatmap(correlation_inside, fmt=\".2f\", cmap='coolwarm', square=True, ax=axs[0])\n",
    "axs[0].set_title(\"Inside SOZ\")\n",
    "axs[0].set_xlabel(\"Time Step (t)\")\n",
    "axs[0].set_ylabel(\"Time Step (t+a)\")\n",
    "\n",
    "sns.heatmap(correlation_outside, fmt=\".2f\", cmap='coolwarm', square=True, ax=axs[1])\n",
    "axs[1].set_title(\"Outside SOZ\")\n",
    "axs[1].set_xlabel(\"Time Step (t)\")\n",
    "axs[1].set_ylabel(\"Time Step (t+a)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para empezar a hacer el proceso de optimizaciòn, vamos primero a fijar la època, y la frequencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data_hgamma_norm\n",
    "f='low gamma'\n",
    "t=60\n",
    "# Extract the upper triangular parts, excluding the diagonal\n",
    "upper_tri_1 = data_outside[t,:,:][np.triu_indices_from(data_outside[t,:,:], k=1)]\n",
    "upper_tri_2 = data_outside[t+1,:,:][np.triu_indices_from(data_outside[t+1,:,:], k=1)]\n",
    "\n",
    "# Calculate Pearson correlation coefficient\n",
    "correlation, p_value = pearsonr(upper_tri_1, upper_tri_2)\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(upper_tri_1, upper_tri_2, alpha=0.7)\n",
    "plt.title(f'Scatter Plot of Upper Triangular Parts\\nPearson Correlation: {correlation:.2f} | P-value: {p_value:.2e} | {f} | t={t} | t+1={t+1}')\n",
    "plt.xlabel('Matrix 1 Upper Triangular Values')\n",
    "plt.ylabel('Matrix 2 Upper Triangular Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {correlation:.2f}\")\n",
    "print(f\"P-value: {p_value:.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The idea is that we are going to substract points in the scatter plot, and we are going to see how the correlation\n",
    "#changes. A point is going to be subtracted if the pearson correlation \n",
    "#improves.\n",
    "\n",
    "# Create a list to store the correlation coefficients\n",
    "\n",
    "correlation_coefficients = []\n",
    "p_values = []\n",
    "#Get an array of the tuples with the names of the channels\n",
    "ch_names_tup=[(ch_names[i],ch_names[j]) for i,j in zip(np.triu_indices_from(data_outside[t, :, :], k=1)[0],np.triu_indices_from(data_outside[t, :, :], k=1)[1])]\n",
    "# Create a list to store the indices of the points to be removed\n",
    "points_to_remove = []\n",
    "\n",
    "for i in range(upper_tri_1.size):\n",
    "    # Create a mask to exclude the i-th point\n",
    "    mask = np.ones(upper_tri_1.size, dtype=bool)\n",
    "    mask[i] = False\n",
    "\n",
    "    # Calculate Pearson correlation coefficient\n",
    "    correlation, p_value = pearsonr(upper_tri_1[mask], upper_tri_2[mask])\n",
    "\n",
    "    # Append the correlation coefficient to the list\n",
    "    correlation_coefficients.append(correlation)\n",
    "    p_values.append(p_value)\n",
    "\n",
    "    # If the correlation coefficient is greater than the previous one, add the index to the list\n",
    "    if i > 0 and correlation > correlation_coefficients[i - 1]:\n",
    "        points_to_remove.append(i)\n",
    "\n",
    "# Create scatter plot with the points to be removed \n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(upper_tri_1, upper_tri_2, alpha=0.7)\n",
    "plt.scatter(upper_tri_1[points_to_remove], upper_tri_2[points_to_remove], color='red', alpha=0.7)\n",
    "plt.title(f'Scatter Plot of Upper Triangular Parts\\n{f} | t={t} | t+1={t+1}')\n",
    "plt.xlabel('Matrix 1 Upper Triangular Values')\n",
    "plt.ylabel('Matrix 2 Upper Triangular Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another approach using signal processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets segment our raw data into epochs\n",
    "epochs=mne.make_fixed_length_epochs(raw, duration=6, preload=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let calculate the time-frequency representation of the data using Morlet wavelets\n",
    "frequencies = np.logspace(1, 2, num=50)\n",
    "\n",
    "# Calculate the time-frequency representation of the data\n",
    "power, phase_locking = spectral_connectivity_epochs(epochs, method='wpli2_debiased', sfreq=raw.info['sfreq'], fmin=1, fmax=100, faverage=True, faverage_params=dict(frequencies=frequencies, use_fft=False))\n",
    "\n",
    "# Get the time points\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Epilep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
