{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired in https://github.com/ljchang/dartbrains/tree/master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We're going to calculate temporal correlation among Region of Interest (ROI) 7\n",
    "#This is tipically done by extracting the temporal response from a seed voxel \n",
    "#or the average response from a seed region. Then this time course is regressed \n",
    "#against all other voxels in the brain to produce a whole brain map of anywhere \n",
    "#that shares a similar time course to the seed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltools.data import Brain_Data, Design_Matrix, Adjacency\n",
    "from nltools.mask import expand_mask, roi_to_brain\n",
    "from nltools.stats import zscore, fdr, one_sample_permutation\n",
    "from nltools.file_reader import onsets_to_dm\n",
    "from nltools.plotting import component_viewer\n",
    "from scipy.stats import binom, ttest_1samp\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from copy import deepcopy\n",
    "import networkx as nx\n",
    "from nilearn.plotting import plot_stat_map, view_img_on_surf\n",
    "from bids import BIDSLayout, BIDSValidator\n",
    "import nibabel as nib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/paosoriom/Universidad/Master Thesis/dev_thesis_SEEG/'\n",
    "data_dir = os.path.join(base_dir, 'data', 'Localizer')\n",
    "layout = BIDSLayout(data_dir, derivatives=True)\n",
    "localizer_path=data_dir\n",
    "#Data extracted from doi:10.1016/j.neuroimage.2015.09.052\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dl.Dataset(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=ds.status(annex='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_list = glob.glob(os.path.join(localizer_path, '*', 'fmriprep', '*', 'func', '*tsv'))\n",
    "file_list = glob.glob(os.path.join(localizer_path, 'derivatives', 'fmriprep', '*', 'func', '*task-localizer_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz'))\n",
    "file_list.sort()\n",
    "file_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prueba\n",
    "result = ds.get(file_list[0])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos necesarios para el ejercicio \n",
    "result = ds.get(os.path.join(localizer_path, 'sub-S01'))\n",
    "result = ds.get(glob.glob(os.path.join(localizer_path, '*.json')))\n",
    "result = ds.get(glob.glob(os.path.join(localizer_path, '*.tsv')))\n",
    "result = ds.get(glob.glob(os.path.join(localizer_path, 'phenotype')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = 'S01'\n",
    "fwhm=6\n",
    "\n",
    "data = Brain_Data(layout.get(subject=sub, task='localizer', scope='derivatives', suffix='bold', extension='nii.gz', return_type='file')[0])\n",
    "smoothed = data.smooth(fwhm=fwhm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed.iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will be using a whole brain parcellation based on similar patterns of\n",
    "#  coactivation across over 10,000 published studies available in \n",
    "# neurosynth (DOI:10.1523/JNEUROSCI.4402-15.2016).\n",
    "#  We will be using a parcellation of 50 different \n",
    "# functionally similar ROIs.\n",
    "mask = Brain_Data('https://neurovault.org/media/images/8423/k50_2mm.nii.gz')\n",
    "\n",
    "mask.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_x = expand_mask(mask)\n",
    "\n",
    "f = mask_x[0:5].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the vmPFC mask (ROI =32) to seed in a functional connectivity \n",
    "# analysis\n",
    "\n",
    "vmpfc = smoothed.extract_roi(mask = mask_x[32])\n",
    "\n",
    "plt.figure (figsize = (15,5))\n",
    "plt.plot(vmpfc, linewidth = 2, color = 'black')\n",
    "plt.title('vmPFC time series', fontsize = 20)\n",
    "plt.xlabel('Time (TR)', fontsize = 15)\n",
    "\n",
    "mask_x[32].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's now build a regression matrix to perform the WHOLE-BRAIN \n",
    "#functional connectivity analysis \n",
    "\n",
    "tr = layout.get_tr()\n",
    "fwhm = 6\n",
    "n_tr = len(data)\n",
    "\n",
    "def make_motion_covariates (mc,tr):\n",
    "    z_mc = zscore(mc)\n",
    "    all_mc = pd.concat([z_mc, z_mc**2, z_mc.diff(),z_mc.diff()**2],axis=1)\n",
    "    all_mc.fillna(0,inplace=True)\n",
    "    return Design_Matrix(all_mc, sampling_freq=1/tr)\n",
    "\n",
    "vmpfc_z = zscore(pd.DataFrame(vmpfc, columns=['vmpfc']))\n",
    "\n",
    "csf_mask = Brain_Data(os.path.join(base_dir, 'mask', 'csf.nii.gz'))\n",
    "csf_mask.plot()\n",
    "csf_mask = csf_mask.threshold(upper = 0.7, binarize=True)\n",
    "csf = zscore(pd.DataFrame(smoothed.extract_roi(mask=csf_mask).T, columns=['csf']))\n",
    "\n",
    "\n",
    "spikes = smoothed.find_spikes(global_spike_cutoff=3, diff_spike_cutoff=3)\n",
    "covariates = pd.read_csv(layout.get(subject=sub, scope='derivatives', extension='.tsv')[0].path, sep='\\t')\n",
    "mc = covariates[['trans_x','trans_y','trans_z','rot_x', 'rot_y', 'rot_z']]\n",
    "mc_cov = make_motion_covariates(mc, tr)\n",
    "dm = Design_Matrix(pd.concat([ \n",
    "pd.Series(vmpfc), csf, mc_cov, spikes.drop(labels='TR', axis=1)], axis=1), sampling_freq=1/tr)\n",
    "dm = dm.add_poly(order=2, include_lower=True)\n",
    "\n",
    "smoothed.X = dm\n",
    "stats = smoothed.regress()\n",
    "\n",
    "vmpfc_conn = stats['beta'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmpfc_conn.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmpfc_conn.iplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis considering Psychophysiological Interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TYPE OF ANALYSIS PROPOSED BY 1053-8119/97 $25.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nib.load(layout.get(subject='S01', scope='raw', suffix='bold')[0].path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bids_events(layout, subject):\n",
    "    '''Create a design_matrix instance from BIDS event file'''\n",
    "    \n",
    "    tr = layout.get_tr()\n",
    "    n_tr = nib.load(layout.get(subject=subject, scope='raw', suffix='bold')[0].path).shape[-1]\n",
    "\n",
    "    onsets = pd.read_csv(layout.get(subject=subject, suffix='events')[0].path, sep='\\t')\n",
    "    onsets.columns = ['Onset', 'Duration', 'Stim']\n",
    "    return onsets_to_dm(onsets, sampling_freq=1/tr, run_length=n_tr)\n",
    "\n",
    "dm = load_bids_events(layout, 'S01')\n",
    "motor_variables = ['video_left_hand','audio_left_hand', 'video_right_hand', 'audio_right_hand']\n",
    "ppi_dm = dm.drop(motor_variables, axis=1)\n",
    "ppi_dm['motor'] = pd.Series(dm.loc[:, motor_variables].sum(axis=1))\n",
    "ppi_dm_conv = ppi_dm.convolve()\n",
    "ppi_dm_conv['vmpfc'] = vmpfc\n",
    "ppi_dm_conv['vmpfc_motor'] = ppi_dm_conv['vmpfc']*ppi_dm_conv['motor_c0']\n",
    "dm = Design_Matrix(pd.concat([ppi_dm_conv, csf, mc_cov, spikes.drop(labels='TR', axis=1)], axis=1), sampling_freq=1/tr)\n",
    "dm = dm.add_poly(order=2, include_lower=True)\n",
    "\n",
    "dm.heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regression analysis and to inspect the interaction term to find regions where \n",
    "# the connectivty profile changes as a function of the motor task\n",
    "smoothed.X = dm\n",
    "ppi_stats = smoothed.regress()\n",
    "\n",
    "vmpfc_motor_ppi = ppi_stats['beta'][int(np.where(smoothed.X.columns=='vmpfc_motor')[0][0])]\n",
    "\n",
    "vmpfc_motor_ppi.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Which regions are more functionally connected with the vmPFC during the motor \n",
    "# conditions \n",
    "vmpfc_motor_ppi.iplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we are trying to explain the variance-covariance structure of a high-dimensional \n",
    "#random vector. PCA help us to find spatial maps or eigenimages\n",
    "#We can start with the residuals of our previous regression, which is the \n",
    "# remaining signal after removing any variance associated with our covariates\n",
    "smoothed_denoised=stats['residual']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 10\n",
    "\n",
    "pca_stats_output = smoothed_denoised.decompose(algorithm='pca', axis='images', n_components=n_components)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_viewer(pca_stats_output, tr=layout.get_tr())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,a = plt.subplots(ncols=2, figsize=(12, 5))\n",
    "a[0].plot(pca_stats_output['decomposition_object'].explained_variance_ratio_)\n",
    "a[0].set_ylabel('Percent Variance Explained', fontsize=18)\n",
    "a[0].set_xlabel('Component', fontsize=18)\n",
    "a[0].set_title('Variance Explained', fontsize=18)\n",
    "a[1].plot(np.cumsum(pca_stats_output['decomposition_object'].explained_variance_ratio_))\n",
    "a[1].set_ylabel('Percent Variance Explained', fontsize=18)\n",
    "a[1].set_xlabel('Component', fontsize=18)\n",
    "a[1].set_title('Cumulative Variance Explained', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach using graph theory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the average time course within each ROI from the 50 parcels \n",
    "#From the denoised data\n",
    "rois = smoothed_denoised.extract_roi(mask=mask)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(rois.T)\n",
    "plt.ylabel('Mean Intensitiy', fontsize=18)\n",
    "plt.xlabel('Time (TRs)', fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the edges of the nodes using pearson correlations. \n",
    "roi_corr = 1 - pairwise_distances(rois, metric='correlation')\n",
    "\n",
    "sns.heatmap(roi_corr, square=True, vmin=-1, vmax=1, cmap='RdBu_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To create a binary matrix, we use an arbitrary threshold in the correlation \n",
    "#matrix\n",
    "a = Adjacency(roi_corr, matrix_type='similarity', labels=[x for x in range(50)])\n",
    "a_thresholded = a.threshold(upper=.6, binarize=True)\n",
    "\n",
    "a_thresholded.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "G = a_thresholded.to_graph()\n",
    "pos = nx.kamada_kawai_layout(G)\n",
    "node_and_degree = G.degree()\n",
    "nx.draw_networkx_edges(G, pos, width=3, alpha=.2)\n",
    "nx.draw_networkx_labels(G, pos, font_size=14, font_color='darkslategray')\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=list(dict(node_and_degree).keys()),\n",
    "                       node_size=[x[1]*100 for x in node_and_degree],\n",
    "                       node_color=list(dict(node_and_degree).values()),\n",
    "                       cmap=plt.cm.Reds_r, linewidths=2, edgecolors='darkslategray', alpha=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dict(G.degree).values())\n",
    "plt.ylabel('Frequency', fontsize=18)\n",
    "plt.xlabel('Degree', fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = pd.Series(dict(G.degree()))\n",
    "brain_degree = roi_to_brain(degree, mask_x)\n",
    "brain_degree.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_img_on_surf(brain_degree.to_nifti())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_x[16].plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
