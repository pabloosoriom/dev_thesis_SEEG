{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "# Authors: Marijn van Vliet <w.m.vanvliet@gmail.com>\n",
    "#          Alex Rockhill <aprockhill@mailbox.org>\n",
    "#\n",
    "# License: BSD-3-Clause\n",
    "\n",
    "import numpy as np\n",
    "import mne\n",
    "from mne.datasets import somato\n",
    "from mne.time_frequency import tfr_morlet, csd_tfr\n",
    "from mne.beamformer import make_dics, apply_dics_tfr_epochs\n",
    "\n",
    "print(__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = somato.data_path()\n",
    "subject = \"01\"\n",
    "task = \"somato\"\n",
    "raw_fname = data_path / f\"sub-{subject}\" / \"meg\" / f\"sub-{subject}_task-{task}_meg.fif\"\n",
    "fname_fwd = (\n",
    "    data_path / \"derivatives\" / f\"sub-{subject}\" / f\"sub-{subject}_task-{task}-fwd.fif\"\n",
    ")\n",
    "subjects_dir = data_path / \"derivatives\" / \"freesurfer\" / \"subjects\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file /home/paosoriom/mne_data/MNE-somato-data/sub-01/meg/sub-01_task-somato_meg.fif...\n",
      "    Range : 237600 ... 506999 =    791.189 ...  1688.266 secs\n",
      "Ready.\n",
      "111 events found\n",
      "Event IDs: [1]\n",
      "Not setting metadata\n",
      "111 matching events found\n",
      "Setting baseline interval to [-0.9989760657919393, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 111 events and 1052 original time points ...\n",
      "    Rejecting  epoch based on MAG : ['MEG 0121']\n",
      "    Rejecting  epoch based on MAG : ['MEG 0121']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on MAG : ['MEG 0211', 'MEG 1331', 'MEG 2211', 'MEG 2241', 'MEG 2521']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on MAG : ['MEG 1641', 'MEG 1831', 'MEG 1921', 'MEG 1941', 'MEG 2241']\n",
      "    Rejecting  epoch based on MAG : ['MEG 1831']\n",
      "    Rejecting  epoch based on MAG : ['MEG 1611']\n",
      "    Rejecting  epoch based on MAG : ['MEG 0211', 'MEG 0441', 'MEG 1631']\n",
      "    Rejecting  epoch based on MAG : ['MEG 1611']\n",
      "    Rejecting  epoch based on MAG : ['MEG 1611', 'MEG 1641']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on MAG : ['MEG 0121', 'MEG 1611', 'MEG 1641']\n",
      "    Rejecting  epoch based on MAG : ['MEG 0121', 'MEG 1611', 'MEG 1631', 'MEG 1641', 'MEG 1941']\n",
      "    Rejecting  epoch based on MAG : ['MEG 0121', 'MEG 0231']\n",
      "    Rejecting  epoch based on MAG : ['MEG 0121', 'MEG 1411']\n",
      "    Rejecting  epoch based on MAG : ['MEG 0121', 'MEG 0211', 'MEG 0231', 'MEG 0341', 'MEG 1621', 'MEG 1811', 'MEG 2211']\n",
      "    Rejecting  epoch based on MAG : ['MEG 0121', 'MEG 0211', 'MEG 1521', 'MEG 1611', 'MEG 1641', 'MEG 1721', 'MEG 1941']\n",
      "    Rejecting  epoch based on MAG : ['MEG 0121']\n",
      "    Rejecting  epoch based on MAG : ['MEG 0211']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on MAG : ['MEG 0121', 'MEG 0211']\n",
      "    Rejecting  epoch based on MAG : ['MEG 0121']\n",
      "    Rejecting  epoch based on MAG : ['MEG 0341']\n",
      "    Rejecting  epoch based on MAG : ['MEG 1911', 'MEG 1921', 'MEG 1931', 'MEG 1941', 'MEG 2111', 'MEG 2121']\n",
      "    Rejecting  epoch based on MAG : ['MEG 0121']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on MAG : ['MEG 2021', 'MEG 2241']\n",
      "    Rejecting  epoch based on MAG : ['MEG 0121', 'MEG 0211', 'MEG 0341']\n",
      "    Rejecting  epoch based on MAG : ['MEG 1341', 'MEG 1611']\n",
      "    Rejecting  epoch based on MAG : ['MEG 0121', 'MEG 0341']\n",
      "    Rejecting  epoch based on MAG : ['MEG 0121']\n",
      "    Rejecting  epoch based on MAG : ['MEG 1611', 'MEG 1641', 'MEG 1831', 'MEG 1911', 'MEG 1941', 'MEG 2011']\n",
      "    Rejecting  epoch based on MAG : ['MEG 0211']\n",
      "    Rejecting  epoch based on MAG : ['MEG 1641']\n",
      "    Rejecting  epoch based on MAG : ['MEG 0211', 'MEG 0221', 'MEG 0231', 'MEG 0241', 'MEG 0341', 'MEG 0441', 'MEG 1611', 'MEG 1621', 'MEG 1641', 'MEG 1731', 'MEG 1911', 'MEG 1921', 'MEG 1941', 'MEG 2041', 'MEG 2241']\n",
      "    Rejecting  epoch based on MAG : ['MEG 0731', 'MEG 1141', 'MEG 2211', 'MEG 2241']\n",
      "    Rejecting  epoch based on MAG : ['MEG 0121', 'MEG 0211', 'MEG 0241', 'MEG 1521', 'MEG 1611', 'MEG 1621', 'MEG 1641', 'MEG 1721']\n",
      "    Rejecting  epoch based on MAG : ['MEG 1611']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on MAG : ['MEG 0211', 'MEG 0221', 'MEG 0231']\n",
      "    Rejecting  epoch based on MAG : ['MEG 0211']\n",
      "    Rejecting  epoch based on MAG : ['MEG 1331', 'MEG 1641', 'MEG 2211', 'MEG 2241']\n",
      "    Rejecting  epoch based on MAG : ['MEG 0231']\n",
      "    Rejecting  epoch based on MAG : ['MEG 1641']\n",
      "    Rejecting  epoch based on MAG : ['MEG 0121']\n",
      "    Rejecting  epoch based on MAG : ['MEG 1131']\n",
      "    Rejecting  epoch based on MAG : ['MEG 0211', 'MEG 0341']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on MAG : ['MEG 0121', 'MEG 0131', 'MEG 0211', 'MEG 0341', 'MEG 1611', 'MEG 1621', 'MEG 1641']\n",
      "    Rejecting  epoch based on MAG : ['MEG 0121', 'MEG 0211', 'MEG 0341']\n",
      "    Rejecting  epoch based on MAG : ['MEG 0121', 'MEG 1611']\n",
      "53 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<EpochsTFR | time : [-0.499488, 2.001282], freq : [13.000000, 31.000000], epochs : 10, channels : 306, ~178.9 MB>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load raw data and make epochs.\n",
    "raw = mne.io.read_raw_fif(raw_fname)\n",
    "events = mne.find_events(raw)\n",
    "epochs = mne.Epochs(\n",
    "    raw,\n",
    "    events,\n",
    "    event_id=1,\n",
    "    tmin=-1,\n",
    "    tmax=2.5,\n",
    "    reject=dict(\n",
    "        grad=5000e-13,  # unit: T / m (gradiometers)\n",
    "        mag=5e-12,  # unit: T (magnetometers)\n",
    "        eog=250e-6,  # unit: V (EOG channels)\n",
    "    ),\n",
    "    preload=True,\n",
    ")\n",
    "epochs = epochs[:10]  # just for speed of execution for the tutorial\n",
    "\n",
    "# We are mostly interested in the beta band since it has been shown to be\n",
    "# active for somatosensory stimulation\n",
    "freqs = np.linspace(13, 31, 5)\n",
    "\n",
    "# Use Morlet wavelets to compute sensor-level time-frequency (TFR)\n",
    "# decomposition for each epoch. We must pass ``output='complex'`` if we wish to\n",
    "# use this TFR later with a DICS beamformer. We also pass ``average=False`` to\n",
    "# compute the TFR for each individual epoch.\n",
    "epochs_tfr = tfr_morlet(\n",
    "    epochs, freqs, n_cycles=5, return_itc=False, output=\"complex\", average=False\n",
    ")\n",
    "\n",
    "# crop either side to use a buffer to remove edge artifact\n",
    "epochs_tfr.crop(tmin=-0.5, tmax=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading forward solution from /home/paosoriom/mne_data/MNE-somato-data/derivatives/sub-01/sub-01_task-somato-fwd.fif...\n",
      "    Reading a source space...\n",
      "    [done]\n",
      "    Reading a source space...\n",
      "    [done]\n",
      "    2 source spaces read\n",
      "    Desired named matrix (kind = 3523) not available\n",
      "    Read MEG forward solution (8155 sources, 306 channels, free orientations)\n",
      "    Source spaces transformed to the forward solution coordinate frame\n",
      "Identifying common channels ...\n",
      "Dropped the following channels:\n",
      "['STI 001', 'STI 002', 'STI 016', 'STI 005', 'STI 015', 'STI 004', 'EOG 061', 'STI 014', 'STI 003', 'STI 006']\n",
      "Identifying common channels ...\n",
      "Computing inverse operator with 306 channels.\n",
      "    306 out of 306 channels remain after picking\n",
      "Selected 306 channels\n",
      "Creating the depth weighting matrix...\n",
      "Whitening the forward solution.\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 2.8e-14 (2.2e-16 eps * 306 dim * 0.4  max singular value)\n",
      "    Estimated rank (mag + grad): 64\n",
      "    MEG: rank 64 computed from 306 data channels with 0 projectors\n",
      "    Setting small MEG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 2.8e-14 (2.2e-16 eps * 306 dim * 0.4  max singular value)\n",
      "    Estimated rank (mag + grad): 64\n",
      "    MEG: rank 64 computed from 306 data channels with 0 projectors\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 8.1e-14 (2.2e-16 eps * 306 dim * 1.2  max singular value)\n",
      "    Estimated rank (mag + grad): 64\n",
      "    MEG: rank 64 computed from 306 data channels with 0 projectors\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 3.8e-14 (2.2e-16 eps * 306 dim * 0.56  max singular value)\n",
      "    Estimated rank (mag + grad): 64\n",
      "    MEG: rank 64 computed from 306 data channels with 0 projectors\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 1.7e-14 (2.2e-16 eps * 306 dim * 0.26  max singular value)\n",
      "    Estimated rank (mag + grad): 64\n",
      "    MEG: rank 64 computed from 306 data channels with 0 projectors\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 9.3e-15 (2.2e-16 eps * 306 dim * 0.14  max singular value)\n",
      "    Estimated rank (mag + grad): 64\n",
      "    MEG: rank 64 computed from 306 data channels with 0 projectors\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 5e-15 (2.2e-16 eps * 306 dim * 0.074  max singular value)\n",
      "    Estimated rank (mag + grad): 64\n",
      "    MEG: rank 64 computed from 306 data channels with 0 projectors\n",
      "Computing DICS spatial filters...\n",
      "    computing DICS spatial filter at 13.0 Hz (1/5)\n",
      "Computing beamformer filters for 8155 sources\n",
      "Filter computation complete\n",
      "    computing DICS spatial filter at 17.5 Hz (2/5)\n",
      "Computing beamformer filters for 8155 sources\n",
      "Filter computation complete\n",
      "    computing DICS spatial filter at 22.0 Hz (3/5)\n",
      "Computing beamformer filters for 8155 sources\n",
      "Filter computation complete\n",
      "    computing DICS spatial filter at 26.5 Hz (4/5)\n",
      "Computing beamformer filters for 8155 sources\n",
      "Filter computation complete\n",
      "    computing DICS spatial filter at 31.0 Hz (5/5)\n",
      "Computing beamformer filters for 8155 sources\n",
      "Filter computation complete\n",
      "Processing epoch : 1\n",
      "Processing epoch : 2\n",
      "Processing epoch : 3\n",
      "Processing epoch : 4\n",
      "Processing epoch : 5\n",
      "Processing epoch : 6\n",
      "Processing epoch : 7\n",
      "Processing epoch : 8\n",
      "Processing epoch : 9\n",
      "Processing epoch : 10\n",
      "[done]\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<SourceEstimate | 8155 vertices, subject : 01, tmin : -499.48803289596964 (ms), tmax : 2001.2820518031856 (ms), tstep : 3.3299202193064645 (ms), data shape : (8155, 752), ~46.9 MB>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the Cross-Spectral Density (CSD) matrix for the sensor-level TFRs.\n",
    "# We are interested in increases in power relative to the baseline period, so\n",
    "# we will make a separate CSD for just that period as well.\n",
    "csd = csd_tfr(epochs_tfr, tmin=-0.5, tmax=2)\n",
    "baseline_csd = csd_tfr(epochs_tfr, tmin=-0.5, tmax=-0.1)\n",
    "\n",
    "# use the CSDs and the forward model to build the DICS beamformer\n",
    "fwd = mne.read_forward_solution(fname_fwd)\n",
    "\n",
    "# compute scalar DICS beamfomer\n",
    "filters = make_dics(\n",
    "    epochs.info,\n",
    "    fwd,\n",
    "    csd,\n",
    "    noise_csd=baseline_csd,\n",
    "    pick_ori=\"max-power\",\n",
    "    reduce_rank=True,\n",
    "    real_filter=True,\n",
    ")\n",
    "\n",
    "# project the TFR for each epoch to source space\n",
    "epochs_stcs = apply_dics_tfr_epochs(epochs_tfr, filters, return_generator=True)\n",
    "\n",
    "# average across frequencies and epochs\n",
    "data = np.zeros((fwd[\"nsource\"], epochs_tfr.times.size))\n",
    "for epoch_stcs in epochs_stcs:\n",
    "    for stc in epoch_stcs:\n",
    "        data += (stc.data * np.conj(stc.data)).real\n",
    "\n",
    "stc.data = data / len(epochs) / len(freqs)\n",
    "\n",
    "# apply a baseline correction\n",
    "stc.apply_baseline((-0.5, -0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not load any valid 3D backend\npyvistaqt: libGL.so.1: cannot open shared object file: No such file or directory\nnotebook: libGL.so.1: cannot open shared object file: No such file or directory\n\n install pyvistaqt, using pip or conda:\n'pip install pyvistaqt'\n'conda install -c conda-forge pyvistaqt'\n\n or install ipywidgets, if using a notebook backend\n'pip install ipywidgets'\n'conda install -c conda-forge ipywidgets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5697/212022006.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m brain = stc.plot(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0msubjects_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubjects_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mhemi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"both\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mviews\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dorsal\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/mne/source_estimate.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, subject, surface, hemi, colormap, time_label, smoothing_steps, transparent, alpha, time_viewer, subjects_dir, figure, views, colorbar, clim, cortex, size, background, foreground, initial_time, time_unit, backend, spacing, title, show_traces, src, volume_options, view_layout, add_data_kwargs, brain_kwargs, verbose)\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m     ):\n\u001b[0;32m--> 740\u001b[0;31m         brain = plot_source_estimates(\n\u001b[0m\u001b[1;32m    741\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-133>\u001b[0m in \u001b[0;36mplot_source_estimates\u001b[0;34m(stc, subject, surface, hemi, colormap, time_label, smoothing_steps, transparent, alpha, time_viewer, subjects_dir, figure, views, colorbar, clim, cortex, size, background, foreground, initial_time, time_unit, backend, spacing, title, show_traces, src, volume_options, view_layout, add_data_kwargs, brain_kwargs, verbose)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/mne/viz/_3d.py\u001b[0m in \u001b[0;36mplot_source_estimates\u001b[0;34m(stc, subject, surface, hemi, colormap, time_label, smoothing_steps, transparent, alpha, time_viewer, subjects_dir, figure, views, colorbar, clim, cortex, size, background, foreground, initial_time, time_unit, backend, spacing, title, show_traces, src, volume_options, view_layout, add_data_kwargs, brain_kwargs, verbose)\u001b[0m\n\u001b[1;32m   2439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2440\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2441\u001b[0;31m                 \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_3d_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2442\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2443\u001b[0m                 \u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No 3D backend found. Resorting to matplotlib 3d.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/mne/viz/backends/renderer.py\u001b[0m in \u001b[0;36m_get_3d_backend\u001b[0;34m()\u001b[0m\n\u001b[1;32m    176\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                 raise RuntimeError(\n\u001b[0m\u001b[1;32m    179\u001b[0m                     \u001b[0;34m\"Could not load any valid 3D backend\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                     \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{key}: {val}\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not load any valid 3D backend\npyvistaqt: libGL.so.1: cannot open shared object file: No such file or directory\nnotebook: libGL.so.1: cannot open shared object file: No such file or directory\n\n install pyvistaqt, using pip or conda:\n'pip install pyvistaqt'\n'conda install -c conda-forge pyvistaqt'\n\n or install ipywidgets, if using a notebook backend\n'pip install ipywidgets'\n'conda install -c conda-forge ipywidgets'"
     ]
    }
   ],
   "source": [
    "fmax = 4500\n",
    "brain = stc.plot(\n",
    "    subjects_dir=subjects_dir,\n",
    "    hemi=\"both\",\n",
    "    views=\"dorsal\",\n",
    "    initial_time=0.55,\n",
    "    brain_kwargs=dict(show=False),\n",
    "    add_data_kwargs=dict(\n",
    "        fmin=fmax / 10,\n",
    "        fmid=fmax / 2,\n",
    "        fmax=fmax,\n",
    "        scale_factor=0.0001,\n",
    "        colorbar_kwargs=dict(label_font_size=10),\n",
    "    ),\n",
    ")\n",
    "\n",
    "# You can save a movie like the one on our documentation website with:\n",
    "# brain.save_movie(tmin=0.55, tmax=1.5, interpolation='linear',\n",
    "#                  time_viewer=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
